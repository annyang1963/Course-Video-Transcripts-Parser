1
00:00:00,000 --> 00:00:02,310
Since I'm a data person and I'm guessing

2
00:00:02,310 --> 00:00:04,950
from the fact that you're taking this class, you are too,

3
00:00:04,950 --> 00:00:09,720
let's take a look at a large data set using that grocery store information at

4
00:00:09,720 --> 00:00:15,090
scale and compare how the data looks first with this big and tall unit table approach.

5
00:00:15,090 --> 00:00:18,240
Then do some quick clean-up and compare the data model size and

6
00:00:18,240 --> 00:00:22,305
other metrics in the VertiPaq analyzer to see how that improves.

7
00:00:22,305 --> 00:00:28,200
We're going to start with 600,000 rows of data and about 34 columns.

8
00:00:28,200 --> 00:00:33,405
I haven't done any transformations to this one just loaded the data set from Excel.

9
00:00:33,405 --> 00:00:37,865
From here, we're going to go ahead and select DAX Studio,

10
00:00:37,865 --> 00:00:43,610
which is one of the external tools so that we can get access to the VertiPaq analyzer and

11
00:00:43,610 --> 00:00:46,700
understand how that data is working in terms of

12
00:00:46,700 --> 00:00:50,605
how we spend our memory and our processing power.

13
00:00:50,605 --> 00:00:53,025
Here we are in DAX Studio.

14
00:00:53,025 --> 00:00:57,100
I'm going to hit "Advanced", "View Metrics".

15
00:00:57,320 --> 00:01:00,900
This is going to give us a wealth of information,

16
00:01:00,900 --> 00:01:04,610
but the key piece that we're going to look at today is column size.

17
00:01:04,610 --> 00:01:08,750
Note that it gives us this handy additional visual cue in

18
00:01:08,750 --> 00:01:12,945
terms of the relative column size to the rest of the data model.

19
00:01:12,945 --> 00:01:14,750
Most of these are pretty small,

20
00:01:14,750 --> 00:01:17,085
some of them are a little bit bigger.

21
00:01:17,085 --> 00:01:22,240
But for now, let's go ahead and eyeball this data sets.

22
00:01:22,240 --> 00:01:24,910
See that were about 6.1 million and

23
00:01:24,910 --> 00:01:29,635
dimensionalize the data model to see how that changes this overall number.

24
00:01:29,635 --> 00:01:34,465
So here we are back in the Power BI section and

25
00:01:34,465 --> 00:01:38,935
you can see we're on the data model pin of Power BI.

26
00:01:38,935 --> 00:01:43,900
We have the customer data now separated out into its own dimension table.

27
00:01:43,900 --> 00:01:48,370
With all of those very interesting columns detailed out connected

28
00:01:48,370 --> 00:01:53,470
to our sales transactions and our product data is separated out as well.

29
00:01:53,470 --> 00:01:56,530
For both dimensions, we've removed duplicates to

30
00:01:56,530 --> 00:02:00,030
ensure that there isn't additional information that repeats,

31
00:02:00,030 --> 00:02:05,300
which also ensures that these different relationships will work correctly.

32
00:02:05,300 --> 00:02:10,175
Let's go to an external tools again and see how this changes our data.

33
00:02:10,175 --> 00:02:12,785
So here we are back at DAX Studio,

34
00:02:12,785 --> 00:02:16,535
and as you can see, the column size overall has reduced.

35
00:02:16,535 --> 00:02:23,065
Recall earlier was about 6.1 million and now we're closer to about 5.5 million.

36
00:02:23,065 --> 00:02:27,470
We can still expand these out and see what additional data

37
00:02:27,470 --> 00:02:31,220
we can glean from this and one thing that pops out right away is that

38
00:02:31,220 --> 00:02:35,495
the customer data dimension has a fair number of

39
00:02:35,495 --> 00:02:39,680
larger individual columns that

40
00:02:39,680 --> 00:02:43,010
don't have information that we're necessarily going to use in our report.

41
00:02:43,010 --> 00:02:48,680
Things like preferred catch phrase or alma mater or a family motto.

42
00:02:48,680 --> 00:02:51,290
So let's go back and reduce some of

43
00:02:51,290 --> 00:02:57,120
these unnecessary columns and see how that changes our overall column size.

44
00:02:58,150 --> 00:03:02,525
Back in Power Query Editor for the customer data dimension,

45
00:03:02,525 --> 00:03:05,570
you can see that I've removed 13 rows with a range

46
00:03:05,570 --> 00:03:09,410
of pieces of information that we know that we're not going to need.

47
00:03:09,410 --> 00:03:12,950
So now that we've reduced the number of columns for this dimension,

48
00:03:12,950 --> 00:03:17,430
Let's see how that changes our data set column size.

49
00:03:26,420 --> 00:03:34,880
Here you can see that we have reduced about a 150k in bytes.

50
00:03:34,880 --> 00:03:36,755
If we look at the customer data,

51
00:03:36,755 --> 00:03:42,890
it really is showing a more useful set of information than say spirit animal,

52
00:03:42,890 --> 00:03:45,740
or alma mater would provide.

53
00:03:45,740 --> 00:03:49,564
But there's still one column

54
00:03:49,564 --> 00:03:53,735
that's been sitting here this whole time eating up all this column data.

55
00:03:53,735 --> 00:03:56,540
Let's check to see whether this is actually useful

56
00:03:56,540 --> 00:04:00,210
for us and see if we can make this a bit smaller.

57
00:04:03,450 --> 00:04:07,450
Back on the Power Query Editor for sales transactions,

58
00:04:07,450 --> 00:04:10,600
we can see that the ID column seems to just

59
00:04:10,600 --> 00:04:14,110
be an index column and it's not really adding any value.

60
00:04:14,110 --> 00:04:20,290
So let's go ahead and remove that and let's see what that does for our model.

61
00:04:21,440 --> 00:04:24,940
Based on the VertiPaq analyzer metrics,

62
00:04:24,940 --> 00:04:28,300
there has been a huge drop by a predictable

63
00:04:28,300 --> 00:04:29,980
four million because there were

64
00:04:29,980 --> 00:04:33,775
about four million bytes being eaten up by just that one column.

65
00:04:33,775 --> 00:04:36,535
But it's still exciting nonetheless.

66
00:04:36,535 --> 00:04:38,455
If we take a look at this,

67
00:04:38,455 --> 00:04:43,255
we can see data that is really earning its bytes.

68
00:04:43,255 --> 00:04:45,700
You've got customer ID for the most part,

69
00:04:45,700 --> 00:04:49,295
taking up the higher column size items,

70
00:04:49,295 --> 00:04:52,625
there are pieces that are a little bit larger like price each,

71
00:04:52,625 --> 00:04:54,695
but we know that we need them.

72
00:04:54,695 --> 00:04:58,220
We know from this that our data model is

73
00:04:58,220 --> 00:05:02,200
at a more optimal size certainly than it was before.

74
00:05:02,200 --> 00:05:05,345
There's one more thing that we can take a look at,

75
00:05:05,345 --> 00:05:07,850
which is the overall file size.

76
00:05:07,850 --> 00:05:10,760
We talked about earlier that beyond column size,

77
00:05:10,760 --> 00:05:17,300
file size provides a general understanding of what the overall size of not only the file,

78
00:05:17,300 --> 00:05:19,435
but also the model is.

79
00:05:19,435 --> 00:05:23,390
If we take a look right here on my folder of

80
00:05:23,390 --> 00:05:26,795
these individual steps for this unit table demo,

81
00:05:26,795 --> 00:05:32,760
you can see we went for about 8,000 down to 7.7,

82
00:05:32,760 --> 00:05:36,600
7.6, and then all the way down to one.

83
00:05:36,600 --> 00:05:43,975
The jump here between the 1,000 to 7.6 was all that single fact column.

84
00:05:43,975 --> 00:05:48,875
Look at the difference that makes as opposed to 13 dimension columns being reduced,

85
00:05:48,875 --> 00:05:55,180
which was between 7,657 kilobytes and 7,633.

86
00:05:55,180 --> 00:05:57,075
So lesson learned here,

87
00:05:57,075 --> 00:05:58,920
definitely create your model,

88
00:05:58,920 --> 00:06:02,165
but keep an eye out for unnecessary fact columns,

89
00:06:02,165 --> 00:06:05,030
especially they are very expensive,

90
00:06:05,030 --> 00:06:09,780
and can really improve your data model anytime you remove them.

